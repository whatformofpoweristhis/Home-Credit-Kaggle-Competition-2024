{"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"sourceId":50160,"databundleVersionId":7921029,"sourceType":"competition"},{"sourceId":8339115,"sourceType":"datasetVersion","datasetId":4952716},{"sourceId":8357130,"sourceType":"datasetVersion","datasetId":4966144},{"sourceId":8413906,"sourceType":"datasetVersion","datasetId":5008050},{"sourceId":8488033,"sourceType":"datasetVersion","datasetId":5063663}],"dockerImageVersionId":30698,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"},"papermill":{"default_parameters":{},"duration":16.068144,"end_time":"2024-05-06T20:14:45.827549","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2024-05-06T20:14:29.759405","version":"2.5.0"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Training Notebooks\n- lgb https://www.kaggle.com/code/arthurroland/lgb-train-notebook\n- cat https://www.kaggle.com/code/arthurroland/cat-train-notebook\n\n## Reference\n- https://www.kaggle.com/code/xiaoleilian/home-credit-ensemble-infer-lgb-cat\n","metadata":{"papermill":{"duration":0.006165,"end_time":"2024-05-06T20:14:32.734827","exception":false,"start_time":"2024-05-06T20:14:32.728662","status":"completed"},"tags":[]}},{"cell_type":"code","source":"import joblib\nfrom pathlib import Path\nimport gc\nfrom glob import glob\nimport numpy as np\nimport pandas as pd\nimport polars as pl\nfrom sklearn.base import BaseEstimator, RegressorMixin\nfrom sklearn.metrics import roc_auc_score\nimport lightgbm as lgb\nimport xgboost as xgb\nimport warnings\nimport datetime\nfrom catboost import CatBoostClassifier, Pool\nwarnings.filterwarnings('ignore')\n\nROOT = '/kaggle/input/home-credit-credit-risk-model-stability'","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","papermill":{"duration":3.969409,"end_time":"2024-05-06T20:14:36.709962","exception":false,"start_time":"2024-05-06T20:14:32.740553","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-05-22T15:21:56.570626Z","iopub.execute_input":"2024-05-22T15:21:56.571075Z","iopub.status.idle":"2024-05-22T15:22:01.600824Z","shell.execute_reply.started":"2024-05-22T15:21:56.571041Z","shell.execute_reply":"2024-05-22T15:22:01.599525Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Pipeline:\n\n    def set_table_dtypes(df):\n        for col in df.columns:\n            if col in [\"case_id\", \"WEEK_NUM\", \"num_group1\", \"num_group2\"]:\n                df = df.with_columns(pl.col(col).cast(pl.Int64))\n            elif col in [\"date_decision\"]:\n                df = df.with_columns(pl.col(col).cast(pl.Date))\n            elif col[-1] in (\"P\", \"A\"):\n                df = df.with_columns(pl.col(col).cast(pl.Float64))\n            elif col[-1] in (\"M\",):\n                df = df.with_columns(pl.col(col).cast(pl.String))\n            elif col[-1] in (\"D\",):\n                df = df.with_columns(pl.col(col).cast(pl.Date))\n        return df\n\n    def handle_dates(df):\n        base_date = datetime.datetime(1900, 1, 1)\n        for col in df.columns:\n            if col[-1] in (\"D\",):\n                days_since_base = (pl.col(col) - pl.lit(base_date)).dt.days()\n                df = df.with_columns(\n                days_since_base.alias(col + \"_days_since_1900_D\")\n                )\n                df = df.with_columns(pl.col(col) - pl.col(\"date_decision\"))  #!!?\n                df = df.with_columns(pl.col(col).dt.total_days()) # t - t-1\n        df = df.drop(\"date_decision\", \"MONTH\")\n        return df\n\n    def filter_cols(df):\n        for col in df.columns:\n            if col not in [\"target\", \"case_id\", \"WEEK_NUM\"]:\n                isnull = df[col].is_null().mean()\n                if isnull > 0.98:\n                    df = df.drop(col)\n        \n        for col in df.columns:\n            if (col not in [\"target\", \"case_id\", \"WEEK_NUM\"]) & (df[col].dtype == pl.String):\n                freq = df[col].n_unique()\n                if (freq == 1) | (freq > 10000):\n                    df = df.drop(col)\n                elif freq>200:\n                    top_20_frequency = (\n                        df.group_by(col)\n                          .agg(pl.count(col).alias(\"counts\"))\n                          .sort(\"counts\", descending=True)\n                          .head(20)\n                    )\n                    value_name = top_20_frequency[col].to_list()\n                    sum_top_20 = top_20_frequency['counts'].sum()\n                    total_non_null = df[col].count()\n                    if sum_top_20 / total_non_null<0.7:\n                        df=df.drop(col)\n                        continue\n                        \n                    df = df.with_columns(\n                        pl.when(pl.col(col).is_in(value_name)).then(pl.col(col)).otherwise(pl.lit(None)).alias(col)\n                    )\n        return df\n\n\n\nclass Aggregator:\n    # Please add or subtract features yourself, be aware that too many features will take up too much space.\n    def num_expr(df):\n        cols = [col for col in df.columns if col[-1] in (\"P\", \"A\")]\n        expr_max = [pl.max(col).alias(f\"max_{col}\") for col in cols]\n\n        expr_last = [pl.last(col).alias(f\"last_{col}\") for col in cols]\n        # expr_first = [pl.first(col).alias(f\"first_{col}\") for col in cols]\n        expr_mean = [pl.mean(col).alias(f\"mean_{col}\") for col in cols]\n        expr_median = [pl.median(col).alias(f\"median_{col}\") for col in cols]\n        expr_var = [pl.var(col).alias(f\"var_{col}\") for col in cols]\n        expr_sum = [pl.sum(col).alias(f\"sum_{col}\") for col in cols]\n\n        return expr_max + expr_last + expr_mean +expr_sum+expr_var\n\n    def date_expr(df):\n        cols = [col for col in df.columns if col[-1] in (\"D\")]\n        expr_max = [pl.max(col).alias(f\"max_{col}\") for col in cols]\n        # expr_min = [pl.min(col).alias(f\"min_{col}\") for col in cols]\n        expr_last = [pl.last(col).alias(f\"last_{col}\") for col in cols]\n        expr_first = [pl.first(col).alias(f\"first_{col}\") for col in cols]\n        expr_mean = [pl.mean(col).alias(f\"mean_{col}\") for col in cols]\n        expr_median = [pl.median(col).alias(f\"median_{col}\") for col in cols]\n\n        return expr_max + expr_last + expr_mean +expr_first\n\n    def str_expr(df):\n        cols = [col for col in df.columns if col[-1] in (\"M\",)]\n        expr_max = [pl.max(col).alias(f\"max_{col}\") for col in cols]\n        # expr_min = [pl.min(col).alias(f\"min_{col}\") for col in cols]\n        expr_last = [pl.last(col).alias(f\"last_{col}\") for col in cols]\n        expr_first = [pl.first(col).alias(f\"first_{col}\") for col in cols]\n        # expr_count = [pl.count(col).alias(f\"count_{col}\") for col in cols]\n        return expr_max + expr_last  +expr_first\n\n    def other_expr(df):\n        cols = [col for col in df.columns if col[-1] in (\"T\", \"L\")]\n        expr_max = [pl.max(col).alias(f\"max_{col}\") for col in cols]\n        # expr_min = [pl.min(col).alias(f\"min_{col}\") for col in cols]\n        expr_last = [pl.last(col).alias(f\"last_{col}\") for col in cols]\n        # expr_first = [pl.first(col).alias(f\"first_{col}\") for col in cols]\n        return expr_max + expr_last\n\n    def count_expr(df):\n        cols = [col for col in df.columns if \"num_group\" in col]\n        expr_max = [pl.max(col).alias(f\"max_{col}\") for col in cols]\n        # expr_min = [pl.min(col).alias(f\"min_{col}\") for col in cols]\n        expr_last = [pl.last(col).alias(f\"last_{col}\") for col in cols]\n        # expr_first = [pl.first(col).alias(f\"first_{col}\") for col in cols]\n        return expr_max + expr_last\n\n    def get_exprs(df):\n        exprs = Aggregator.num_expr(df) + \\\n                Aggregator.date_expr(df) + \\\n                Aggregator.str_expr(df) + \\\n                Aggregator.other_expr(df) + \\\n                Aggregator.count_expr(df)\n\n        return exprs","metadata":{"papermill":{"duration":0.033027,"end_time":"2024-05-06T20:14:36.748557","exception":false,"start_time":"2024-05-06T20:14:36.715530","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-05-22T15:22:01.603025Z","iopub.execute_input":"2024-05-22T15:22:01.603642Z","iopub.status.idle":"2024-05-22T15:22:01.747570Z","shell.execute_reply.started":"2024-05-22T15:22:01.603608Z","shell.execute_reply":"2024-05-22T15:22:01.746450Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def read_file(path, depth=None):\n    df = pl.read_parquet(path)\n    df = df.pipe(Pipeline.set_table_dtypes)\n    if depth in [1,2]:\n        df = df.group_by(\"case_id\").agg(Aggregator.get_exprs(df)) \n    return df\n\ndef read_files(regex_path, depth=None):\n    chunks = []\n    \n    for path in glob(str(regex_path)):\n        df = pl.read_parquet(path)\n        df = df.pipe(Pipeline.set_table_dtypes)\n        if depth in [1, 2]:\n            df = df.group_by(\"case_id\").agg(Aggregator.get_exprs(df))\n        chunks.append(df)\n    \n    df = pl.concat(chunks, how=\"vertical_relaxed\")\n    df = df.unique(subset=[\"case_id\"])\n    return df\n\n\ndef feature_eng(df_base, depth_0, depth_1, depth_2):\n    df_base = (\n        df_base\n        .with_columns(\n            month_decision = pl.col(\"date_decision\").dt.month(),\n            weekday_decision = pl.col(\"date_decision\").dt.weekday(),\n        )\n    )\n    for i, df in enumerate(depth_0 + depth_1 + depth_2):\n        df_base = df_base.join(df, how=\"left\", on=\"case_id\", suffix=f\"_{i}\")\n    df_base = df_base.pipe(Pipeline.handle_dates)\n    return df_base\n\n\ndef to_pandas(df_data, cat_cols=None):\n    df_data = df_data.to_pandas()\n    if cat_cols is None:\n        cat_cols = list(df_data.select_dtypes(\"object\").columns)\n    df_data[cat_cols] = df_data[cat_cols].astype(\"category\")\n    return df_data, cat_cols\n\n\ndef reduce_mem_usage(df):\n    \"\"\" iterate through all the columns of a dataframe and modify the data type\n        to reduce memory usage.        \n    \"\"\"\n    start_mem = df.memory_usage().sum() / 1024**2\n    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n    \n    for col in df.columns:\n        col_type = df[col].dtype\n        if str(col_type)==\"category\":\n            continue\n        \n        if col_type != object:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n        else:\n            continue\n    end_mem = df.memory_usage().sum() / 1024**2\n    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n    \n    return df","metadata":{"papermill":{"duration":0.02643,"end_time":"2024-05-06T20:14:36.780211","exception":false,"start_time":"2024-05-06T20:14:36.753781","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-05-22T15:22:01.749358Z","iopub.execute_input":"2024-05-22T15:22:01.749793Z","iopub.status.idle":"2024-05-22T15:22:01.784851Z","shell.execute_reply.started":"2024-05-22T15:22:01.749754Z","shell.execute_reply":"2024-05-22T15:22:01.783426Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Load Models","metadata":{"papermill":{"duration":0.004957,"end_time":"2024-05-06T20:14:36.790691","exception":false,"start_time":"2024-05-06T20:14:36.785734","status":"completed"},"tags":[]}},{"cell_type":"code","source":"lgb_notebook_info = joblib.load('/kaggle/input/lgb-model-v2/notebook_info.joblib')\nprint(f\"- [lgb] notebook_start_time: {lgb_notebook_info['notebook_start_time']}\")\nprint(f\"- [lgb] description: {lgb_notebook_info['description']}\")\n\nlgb_cols = lgb_notebook_info['cols']\nlgbcat_cols = lgb_notebook_info['cat_cols']\n# less_important_features=['applicationcnt_361L', 'clientscnt_157L', 'clientscnt_257L', 'deferredmnthsnum_166L', 'for3years_128L', 'formonth_206L', 'forquarter_1017L', 'forquarter_462L', 'forweek_1077L', 'forweek_601L', 'foryear_818L', 'max_pmts_month_158T', 'last_classificationofcontr_13M', 'last_classificationofcontr_400M', 'last_contractst_545M', 'last_description_351M', 'last_financialinstitution_591M', 'last_purposeofcred_426M', 'last_subjectrole_93M', 'max_contracttype_653M', 'max_pmtmethod_731M', 'max_purposeofcred_722M', 'max_subjectrole_326M', 'last_classificationofcontr_1114M', 'last_periodicityofpmts_997M', 'last_purposeofcred_722M', 'last_subjectrole_326M', 'min_contracttype_653M', 'max_empladdr_district_926M', 'max_empladdr_zipcode_114M', 'last_education_927M', 'last_empladdr_district_926M', 'last_empladdr_zipcode_114M', 'max_contaddr_matchlist_1032L', 'max_collater_typofvalofguarant_298M', 'max_collater_typofvalofguarant_407M', 'last_collater_typofvalofguarant_298M', 'last_collater_typofvalofguarant_407M', 'last_collaterals_typeofguarante_359M', 'last_collaterals_typeofguarante_669M', 'last_subjectroles_name_541M', 'last_subjectroles_name_838M', 'max_cacccardblochreas_147M', 'max_empls_economicalst_849M', 'last_empls_economicalst_849M']\n# cat_cols = [item for item in cat_cols if item not in less_important_features]\nprint(f\"- [lgb] len(cols): {len(lgb_cols)}\")\nprint(f\"- [lgb] len(cat_cols): {len(lgbcat_cols)}\")\nprint(\"avg auc is 0.8611\")\nlgb_models = joblib.load('/kaggle/input/lgb-model-v2/lgb_models.joblib')\nlgb_models","metadata":{"papermill":{"duration":0.900175,"end_time":"2024-05-06T20:14:37.696154","exception":false,"start_time":"2024-05-06T20:14:36.795979","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-05-22T15:22:01.788867Z","iopub.execute_input":"2024-05-22T15:22:01.789410Z","iopub.status.idle":"2024-05-22T15:22:03.099743Z","shell.execute_reply.started":"2024-05-22T15:22:01.789366Z","shell.execute_reply":"2024-05-22T15:22:03.098514Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cat_notebook_info = joblib.load('/kaggle/input/cat-model-15000iter/notebook_info (10).joblib')\nprint(f\"- [cat] notebook_start_time: {cat_notebook_info['notebook_start_time']}\")\nprint(f\"- [cat] description: {cat_notebook_info['description']}\")\ncab_cols = cat_notebook_info['cols']\ncabcat_cols = cat_notebook_info['cat_cols']\nprint(f\"- [cat] len(cols): {len(cab_cols)}\")\nprint(f\"- [cat] len(cat_cols): {len(cabcat_cols)}\")\ncat_models = joblib.load('/kaggle/input/cat-model-15000iter/cat_models (11).joblib')\ncat_models","metadata":{"papermill":{"duration":4.057991,"end_time":"2024-05-06T20:14:41.759698","exception":false,"start_time":"2024-05-06T20:14:37.701707","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-05-22T15:22:03.101089Z","iopub.execute_input":"2024-05-22T15:22:03.101550Z","iopub.status.idle":"2024-05-22T15:22:09.571359Z","shell.execute_reply.started":"2024-05-22T15:22:03.101520Z","shell.execute_reply":"2024-05-22T15:22:09.570179Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# xgb_notebook_info=joblib.load('/kaggle/input/xgb-model-ensemble/notebook_info')\n# best_iteration=xgb_notebook_info['best_iteration']\n# xgb_model=joblib.load('/kaggle/input/xgb-model-ensemble/xgb_models.joblib')","metadata":{"papermill":{"duration":0.053656,"end_time":"2024-05-06T20:14:41.819102","exception":false,"start_time":"2024-05-06T20:14:41.765446","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-05-22T15:22:09.572725Z","iopub.execute_input":"2024-05-22T15:22:09.573097Z","iopub.status.idle":"2024-05-22T15:22:09.577505Z","shell.execute_reply.started":"2024-05-22T15:22:09.573067Z","shell.execute_reply":"2024-05-22T15:22:09.576482Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Prepare df_test","metadata":{"papermill":{"duration":0.005502,"end_time":"2024-05-06T20:14:41.830569","exception":false,"start_time":"2024-05-06T20:14:41.825067","status":"completed"},"tags":[]}},{"cell_type":"code","source":"ROOT            = Path(\"/kaggle/input/home-credit-credit-risk-model-stability\")\n\nTEST_DIR        = ROOT / \"parquet_files\" / \"test\"\n\ndata_store = {\n    \"df_base\": read_file(TEST_DIR / \"test_base.parquet\"),\n    \"depth_0\": [\n        read_file(TEST_DIR / \"test_static_cb_0.parquet\"),\n        read_files(TEST_DIR / \"test_static_0_*.parquet\"),\n    ],\n    \"depth_1\": [\n        read_files(TEST_DIR / \"test_applprev_1_*.parquet\", 1),\n        read_file(TEST_DIR / \"test_tax_registry_a_1.parquet\", 1),\n        read_file(TEST_DIR / \"test_tax_registry_b_1.parquet\", 1),\n        read_file(TEST_DIR / \"test_tax_registry_c_1.parquet\", 1),\n        read_files(TEST_DIR / \"test_credit_bureau_a_1_*.parquet\", 1),\n        read_file(TEST_DIR / \"test_credit_bureau_b_1.parquet\", 1),\n        read_file(TEST_DIR / \"test_other_1.parquet\", 1),\n        read_file(TEST_DIR / \"test_person_1.parquet\", 1),\n        read_file(TEST_DIR / \"test_deposit_1.parquet\", 1),\n        read_file(TEST_DIR / \"test_debitcard_1.parquet\", 1),\n    ],\n    \"depth_2\": [\n        read_file(TEST_DIR / \"test_credit_bureau_b_2.parquet\", 2),\n        read_files(TEST_DIR / \"test_credit_bureau_a_2_*.parquet\", 2),\n        read_file(TEST_DIR / \"test_applprev_2.parquet\", 2),\n        read_file(TEST_DIR / \"test_person_2.parquet\", 2)\n    ]\n}","metadata":{"papermill":{"duration":0.529427,"end_time":"2024-05-06T20:14:42.365673","exception":false,"start_time":"2024-05-06T20:14:41.836246","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-05-22T15:22:09.578761Z","iopub.execute_input":"2024-05-22T15:22:09.579100Z","iopub.status.idle":"2024-05-22T15:22:10.187916Z","shell.execute_reply.started":"2024-05-22T15:22:09.579071Z","shell.execute_reply":"2024-05-22T15:22:10.186695Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test = feature_eng(**data_store)\nprint(\"test data shape:\\t\", df_test.shape)\ndel data_store\ngc.collect()\n\ncols=pd.unique(lgb_cols + cab_cols).tolist()\ndf_test = df_test.select(['case_id'] + cols)\n\ndf_test, cat_cols = to_pandas(df_test, lgbcat_cols)\ndf_test = reduce_mem_usage(df_test)\ndf_test = df_test.set_index('case_id')\nprint(\"test data shape:\\t\", df_test.shape)\n\ngc.collect()","metadata":{"papermill":{"duration":0.894302,"end_time":"2024-05-06T20:14:43.267896","exception":false,"start_time":"2024-05-06T20:14:42.373594","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-05-22T15:22:10.189488Z","iopub.execute_input":"2024-05-22T15:22:10.189910Z","iopub.status.idle":"2024-05-22T15:22:11.068431Z","shell.execute_reply.started":"2024-05-22T15:22:10.189873Z","shell.execute_reply":"2024-05-22T15:22:11.066960Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in cab_cols:\n    if i not in df_test.columns:\n        print(i)","metadata":{"papermill":{"duration":0.016307,"end_time":"2024-05-06T20:14:43.290548","exception":false,"start_time":"2024-05-06T20:14:43.274241","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-05-22T15:22:11.069850Z","iopub.execute_input":"2024-05-22T15:22:11.070198Z","iopub.status.idle":"2024-05-22T15:22:11.077054Z","shell.execute_reply.started":"2024-05-22T15:22:11.070170Z","shell.execute_reply":"2024-05-22T15:22:11.075779Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test","metadata":{"papermill":{"duration":0.056962,"end_time":"2024-05-06T20:14:43.353785","exception":false,"start_time":"2024-05-06T20:14:43.296823","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-05-22T15:22:11.081515Z","iopub.execute_input":"2024-05-22T15:22:11.082030Z","iopub.status.idle":"2024-05-22T15:22:11.138911Z","shell.execute_reply.started":"2024-05-22T15:22:11.081968Z","shell.execute_reply":"2024-05-22T15:22:11.137388Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Voting Model","metadata":{"papermill":{"duration":0.006751,"end_time":"2024-05-06T20:14:43.367868","exception":false,"start_time":"2024-05-06T20:14:43.361117","status":"completed"},"tags":[]}},{"cell_type":"code","source":"class VotingModel(BaseEstimator, RegressorMixin):\n    def __init__(self, estimators):\n        super().__init__()\n        self.estimators = estimators\n        \n    def fit(self, X, y=None):\n        return self\n    \n    def predict(self, X):\n        y_preds = [estimator.predict(X) for estimator in self.estimators]\n        return np.mean(y_preds, axis=0)\n     \n    def predict_proba(self, X):      \n        # lgb\n        lgb_X=X[lgb_cols]\n        nums=lgb_X.select_dtypes(exclude='category').columns\n        lgb_X[nums] = lgb_X[nums].fillna(0)\n        y_preds = [estimator.predict_proba(lgb_X) for estimator in self.estimators[:5]]\n        del lgb_X\n        gc.collect()\n        \n        # cat \n        X[cabcat_cols] = X[cabcat_cols].astype(str)\n        y_preds += [estimator.predict_proba(X[cab_cols]) for estimator in self.estimators[-5:]]\n        \n        return np.mean(y_preds, axis=0)\n        ","metadata":{"papermill":{"duration":0.022416,"end_time":"2024-05-06T20:14:43.397589","exception":false,"start_time":"2024-05-06T20:14:43.375173","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-05-22T15:22:11.140405Z","iopub.execute_input":"2024-05-22T15:22:11.140773Z","iopub.status.idle":"2024-05-22T15:22:11.155272Z","shell.execute_reply.started":"2024-05-22T15:22:11.140742Z","shell.execute_reply":"2024-05-22T15:22:11.154042Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = VotingModel(lgb_models+cat_models)\nlen(model.estimators)","metadata":{"papermill":{"duration":0.021926,"end_time":"2024-05-06T20:14:43.426671","exception":false,"start_time":"2024-05-06T20:14:43.404745","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-05-22T15:22:11.157089Z","iopub.execute_input":"2024-05-22T15:22:11.157517Z","iopub.status.idle":"2024-05-22T15:22:11.166717Z","shell.execute_reply.started":"2024-05-22T15:22:11.157480Z","shell.execute_reply":"2024-05-22T15:22:11.165065Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = pd.Series(model.predict_proba(df_test)[:, 1], index=df_test.index)\ndf_subm = pd.read_csv(ROOT / \"sample_submission.csv\")\ndf_subm = df_subm.set_index(\"case_id\")\n\ndf_subm['score'] = y_pred\ndf_subm.to_csv(\"submission.csv\")\ndf_subm","metadata":{"papermill":{"duration":1.246799,"end_time":"2024-05-06T20:14:44.681080","exception":false,"start_time":"2024-05-06T20:14:43.434281","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-05-22T15:22:11.168095Z","iopub.execute_input":"2024-05-22T15:22:11.168445Z","iopub.status.idle":"2024-05-22T15:22:12.483655Z","shell.execute_reply.started":"2024-05-22T15:22:11.168416Z","shell.execute_reply":"2024-05-22T15:22:12.482364Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"papermill":{"duration":0.006827,"end_time":"2024-05-06T20:14:44.695434","exception":false,"start_time":"2024-05-06T20:14:44.688607","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]}]}